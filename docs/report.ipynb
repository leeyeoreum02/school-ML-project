{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0398ae28537543c2874f70f75e7447595c9b88bf635e0c674d071e3c823adfec9",
   "display_name": "Python 3.9.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. Get Data\n",
    "\n",
    "## 1.1 Requirements\n",
    "- please refer to requirements.txt to check libraries used in this project\n",
    "\n",
    "## 1.2 Download Data\n",
    "- Data\n",
    "    - gender_submission.csv (submission)\n",
    "    - test.csv (test data)\n",
    "    - train.csv (train data)\n",
    "- Download\n",
    "    - using Kaggle API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "source": [
    "# 2. Data Analyze\n",
    "\n",
    "## 2.1 Overview Data\n",
    "- Label\n",
    "    - Survived\n",
    "- Column that has null value -> have to process\n",
    "    - Age\n",
    "    - Cabin\n",
    "    - Embarked\n",
    "- Categorical column -> have to encoding\n",
    "    - Pclass: already ordinal encoded\n",
    "    - Sex\n",
    "    - Embarked\n",
    "- Correlation of columns\n",
    "    - direct proportion with label('Survived'):\n",
    "        - Fare\n",
    "        - Pclass: In fact, the larger class of Pclass, the lower value it has, therefore correlation label with Pclass is actually direcr proportion / Fare and Pclass are direct proportion\n",
    "    - inverse proportion\n",
    "        - Parch: It looks like direct propotion in corr matrix because of outlier, In fact, we can check out that's not true in scatter matrix\n",
    "        - SibSp\n",
    "        - Age\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b6f850db362d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from load_data import load_titanic_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'load_titanic_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6dacd9e1a8a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_titanic_data' is not defined"
     ]
    }
   ],
   "source": [
    "titanic = load_titanic_data('train')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d013d6c494b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8e3cac7b5250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a3de8a95a948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6d8effb51e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-df9efb526d92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Parch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fare'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6dffbb672bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m titanic['Age_cat'] = pd.cut(titanic['Age'],\n\u001b[0m\u001b[0;32m      2\u001b[0m                                \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                labels=[1, 2, 3, 4, 5, 6])\n\u001b[0;32m      4\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age_cat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Age_cat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "titanic['Age_cat'] = pd.cut(titanic['Age'],\n",
    "                               bins=[0., 10., 20., 30., 40., 50., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5, 6])\n",
    "titanic['Age_cat'].hist()\n",
    "titanic.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-99dc9ab032e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "corr_matrix = titanic.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'corr_matrix' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fec1d392a6ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corr_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "corr_matrix['Survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d439e3d089a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Parch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fare'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscatter_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch','Fare']\n",
    "scatter_matrix(titanic[attributes], figsize=(12, 8), alpha=0.1)"
   ]
  },
  {
   "source": [
    "# 3. Preprocessing Data (preprocessing.py)\n",
    "\n",
    "## 3.1 Data Cleaning\n",
    "- Data Shuffle\n",
    "- Delete unnecessary column\n",
    "    - Name: no matter to train good model\n",
    "    - Ticket: too many text values to encode\n",
    "    - Cabin: too many null and text values\n",
    "    - Embarked: I think it isn't related to survival so much\n",
    "- Process null values\n",
    "    - Age: fill null with median\n",
    "- Standardize\n",
    "- Process categorical column\n",
    "    - Sex: female:0, male:1 (used OrdinalEncoder)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic_data(mode: str) -> pd.DataFrame:\n",
    "    TRAIN_PATH = os.path.join('data', 'train.csv')\n",
    "    TEST_PATH = os.path.join('data', 'test.csv')\n",
    "    modes = {'train': TRAIN_PATH, 'test': TEST_PATH}\n",
    "    csv_path = os.path.join(modes[mode])\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(mode):\n",
    "    titanic = load_titanic_data(mode)\n",
    "    if mode == 'train':\n",
    "        shuffled_titanic = titanic.sample(frac=1)\n",
    "        shuffled_titanic = shuffled_titanic.drop('PassengerId', axis=1)\n",
    "        # print(shuffled_titanic.head())\n",
    "        # print(shuffled_titanic.head())\n",
    "        x_data, t_data = shuffled_titanic.drop('Survived', axis=1), \\\n",
    "                        shuffled_titanic['Survived'].copy()\n",
    "\n",
    "        x_data_num = x_data.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "        num_attribs = list(x_data_num)\n",
    "        cat_attribs = ['Sex']\n",
    "        # print('attribs:', num_attribs + cat_attribs)\n",
    "\n",
    "        num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "            \n",
    "        full_pipeline = ColumnTransformer([\n",
    "            ('num', num_pipeline, num_attribs),\n",
    "            ('cat', OrdinalEncoder(), cat_attribs),\n",
    "        ])\n",
    "\n",
    "        x_data_prepared = full_pipeline.fit_transform(x_data)\n",
    "        t_data = np.array(t_data, dtype=np.uint8)\n",
    "        \n",
    "        return x_data_prepared, t_data\n",
    "    elif mode == 'test':\n",
    "        titanic_num = titanic.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "        num_attribs = list(titanic_num)\n",
    "        cat_attribs = ['Sex']\n",
    "        # print(titanic_num.head())\n",
    "\n",
    "        num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "            \n",
    "        full_pipeline = ColumnTransformer([\n",
    "            ('num', num_pipeline, num_attribs),\n",
    "            ('cat', OrdinalEncoder(), cat_attribs),\n",
    "        ])\n",
    "\n",
    "        titanic_prepared = full_pipeline.fit_transform(titanic)\n",
    "\n",
    "        return titanic_prepared"
   ]
  },
  {
   "source": [
    "# 4. Training Model\n",
    "\n",
    "- validation strategy: using stratified k-fold to avoid data bias and overfitting\n",
    "\n",
    "- (model) SGD Classifier\n",
    "    - Review: Regularization showed better performance. non-regularization, rasso SGD Classifier showed overfitting.\n",
    "    - score example:\n",
    "        - non-regularization:\n",
    "            - accuracy(5-fold validation): \\[0.68, 0.78, 0.79, 0.76, 0.76]\n",
    "            - confusion matrix: \\[\\[429 120]\n",
    "                                \\[ 78 264]]\n",
    "            - precision score: 0.69\n",
    "            - recall score: 0.77\n",
    "            - f1 score: 0.72\n",
    "            - kaggle submission score(accuracy): 0.71\n",
    "        - rasso regularization:\n",
    "            - accuracy(5-fold validation): \\[0.68, 0.78, 0.79, 0.76, 0.77]\n",
    "            - confusion matrix: \\[\\[442 107]\n",
    "                                \\[ 95 247]]\n",
    "            - precision score: 0.70\n",
    "            - recall score: 0.72\n",
    "            - f1 score: 0.71\n",
    "            - kaggle submission score(accuracy): 0.72\n",
    "        - ridge regularization:\n",
    "            - accuracy(5-fold validation): \\[0.75, 0.73, 0.78, 0.79, 0.73]\n",
    "            - confusion matrix: \\[\\[397 152]\n",
    "                                \\[ 71 271]]\n",
    "            - precision score: 0.64\n",
    "            - recall score: 0.79\n",
    "            - f1 score: 0.71\n",
    "            - kaggle submission score(accuracy): 0.76\n",
    "        - elastic regularization:\n",
    "            - accuracy(5-fold validation): \\[0.75, 0.73, 0.78, 0.79, 0.73]\n",
    "            - confusion matrix: \\[\\[486  63]\n",
    "                                \\[125 217]]\n",
    "            - precision score: 0.78\n",
    "            - recall score: 0.63\n",
    "            - f1 score: 0.70\n",
    "            - kaggle submission score(accuracy): 0.76\n",
    "\n",
    "- (model) Logistic Regression\n",
    "- Review: Regularization didn't show better performance. it showed overfitting little bit.\n",
    "- score example:\n",
    "    - non-regularization:\n",
    "        - accuracy(5-fold validation): \\[0.79, 0.75, 0.80, 0.81, 0.81]\n",
    "        - confusion matrix: \\[\\[471  78]\n",
    "                            \\[101 241]]\n",
    "        - precision score: 0.76\n",
    "        - recall score: 0.70\n",
    "        - f1 score: 0.73\n",
    "        - kaggle submission score(accuracy): 0.76\n",
    "    - ridge regularization(default):\n",
    "        - accuracy(5-fold validation): \\[0.79, 0.75, 0.80, 0.82, 0.81]\n",
    "        - confusion matrix: \\[\\[474 75]\n",
    "                            \\[101 241]]\n",
    "        - precision score: 0.76\n",
    "        - recall score: 0.70\n",
    "        - f1 score: 0.73\n",
    "        - kaggle submission score(accuracy): 0.76\n",
    "\n",
    "- (model) Support Vector Classifier\n",
    "    - Review: This model showed better performance than SGDClassifier, LogisticRegression but there was overfitting.\n",
    "    - score example:\n",
    "        - non-regularization\n",
    "            - accuracy(5-fold validation): \\[0.82, 0.81, 0.87, 0.80, 0.82]\n",
    "            - confusion matrix: \\[\\[499  50]\n",
    "                                \\[ 99 243]]\n",
    "            - precision score: 0.83\n",
    "            - recall score: 0.71\n",
    "            - f1 score: 0.77\n",
    "            - kaggle submission score(accuracy): 0.78\n",
    "\n",
    "- (model) Random Forest Classifier\n",
    "    - Review: First emsemble model, it showed better performance than single model but there was overfitting little bit.\n",
    "    - score example:\n",
    "        - accuracy(5-fold validation): \\[0.78, 0.79, 0.90, 0.80, 0.80]\n",
    "        - confusion matrix: \\[\\[527  22]\n",
    "                            \\[ 26 316]]\n",
    "        - precision score: 0.93\n",
    "        - recall score: 0.92\n",
    "        - f1 score: 0.93\n",
    "        - kaggle submission score(accuracy): 0.77\n",
    "\n",
    "- (model) Voting Classifier\n",
    "    - Review: Ensemble model, it used estimators that are model used before. it showed better performance than single model too. there was no critical overfitting.\n",
    "    - score example:\n",
    "        - accuracy(5-fold validation): \\[0.80, 0.77, 0.83, 0.81, 0.83]\n",
    "        - confusion matrix: \\[\\[501  48]\n",
    "                            \\[112 230]]\n",
    "        - precision score: 0.83\n",
    "        - recall score: 0.67\n",
    "        - f1 score: 0.74\n",
    "        - kaggle submission score(accuracy): 0.78\n",
    "\n",
    "- (model) Bagging Classifier: didn't use because it's known that it didn't show good performance in small dataset.\n",
    "\n",
    "- (model) AdaBoost Classifier\n",
    "    - Review: Ensemble model, it used Decision Tree. it showed worse preformance than single model. there was overfitting.\n",
    "    - score example:\n",
    "        - accuracy(5-fold validation): \\[0.85, 0.81, 0.78, 0.81, 0.77]\n",
    "        - confusion matrix: \\[\\[478  71]\n",
    "                            \\[ 79 263]]\n",
    "        - precision score: 0.79\n",
    "        - recall score: 0.77\n",
    "        - f1 score: 0.78\n",
    "        - kaggle submission score(accuracy): 0.75\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ccdf5707c930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_preprocessed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_preprocessed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msubmit_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/gender_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e4139f909e63>\u001b[0m in \u001b[0;36mload_preprocessed_data\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# print('attribs:', num_attribs + cat_attribs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         num_pipeline = Pipeline([\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m'imputer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[1;34m'std_scaler'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "X_data, y_data = load_preprocessed_data('train')\n",
    "test_data = load_preprocessed_data('test')\n",
    "submit_data = pd.read_csv('data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(penalty='none')\n",
    "rasso_sgd = SGDClassifier(penalty='l1')\n",
    "ridge_sgd = SGDClassifier(penalty='l2')\n",
    "elastic_sgd = SGDClassifier(penalty='elasticnet')\n",
    "log_clf = LogisticRegression(penalty='none')\n",
    "ridge_log = LogisticRegression() # ridge regulization is default\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "models = {\n",
    "    '0': sgd_clf, \n",
    "    '1': rasso_sgd, \n",
    "    '2': ridge_sgd, \n",
    "    '3': elastic_sgd, \n",
    "    '4': log_clf, \n",
    "    '5': ridge_log,\n",
    "    '6': rnd_clf,\n",
    "    '7': svm_clf\n",
    "    }\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(key, model) for key, model in models.items()],\n",
    "    voting='hard'\n",
    ")\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm='SAMME.R', learning_rate=0.5\n",
    ")\n",
    "\n",
    "models.update({\n",
    "    '8': voting_clf,\n",
    "    '9': ada_clf\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-543c51f92007>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mX_train_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my_train_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_data' is not defined"
     ]
    }
   ],
   "source": [
    "skfolds = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "for clf in models.values():\n",
    "    scores = []\n",
    "    for train_index, test_index in skfolds.split(X_data, y_data):\n",
    "        X_train_folds = X_data[train_index]\n",
    "        y_train_folds = y_data[train_index]\n",
    "        X_test_fold = X_data[test_index]\n",
    "        y_test_fold = y_data[test_index]\n",
    "\n",
    "        clf.fit(X_train_folds, y_train_folds)\n",
    "        y_pred = clf.predict(X_test_fold)\n",
    "        score = sum(y_pred == y_test_fold) / len(y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    print('clf:', clf, ', scores:', scores)\n",
    "\n",
    "    y_pred = clf.predict(X_data)\n",
    "    print('confusion matrix:\\n', confusion_matrix(y_data, y_pred))\n",
    "    print('precision_score:', precision_score(y_data, y_pred), \\\n",
    "    ', recall score:', recall_score(y_data, y_pred), ', f1 score:', \\\n",
    "        f1_score(y_data, y_pred), '\\n')\n",
    "    \n",
    "    prediction = clf.predict(test_data)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': submit_data['PassengerId'],\n",
    "        'Survived': prediction\n",
    "    })\n",
    "\n",
    "    if clf == voting_clf:\n",
    "        name = 'VotingClassifier'\n",
    "    elif clf == ada_clf:\n",
    "        name = 'AdaBoostClassifier'\n",
    "    else:\n",
    "        name = clf\n",
    "\n",
    "    submission.to_csv(f'data/{name}_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n",
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|██████████| 3.18k/3.18k [00:00<00:00, 24.1kB/s]\n",
      "100%|██████████| 3.18k/3.18k [00:04<00:00, 717B/s]  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f data\\gender_submission.csv -m \"test\""
   ]
  },
  {
   "source": [
    "### Conclusion: Ensemble model showed better performance than single model usually. But among single model, Support Vector Classifier showed good performance like ensemble model. Also regularized model generally showed better performance in kaggle submission that predicts 'test.csv' data(non-label) because it prevents overfitting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}